{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58794d33",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0872b",
   "metadata": {},
   "source": [
    "Inference on simulational parameters is carried out employing Sequential Neural Posterior Estimation (SNPE), implemented by the sbi package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea001b6",
   "metadata": {},
   "source": [
    "### A. Imports and preliminary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669835e",
   "metadata": {},
   "source": [
    "First of all, the relevant imports are carried out in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff30a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n# Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\n\\nsys.path.append(\\\"../\\\")\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\n# Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n# Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\n\\nsys.path.append(\\\"../\\\")\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\n# Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Just a formatting related plugin\n",
    "%load_ext nb_black\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import arviz\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import sbi\n",
    "import sbi.utils as sbi_utils\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import torch\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import ttest_ind\n",
    "from snpe.inference import inference_class\n",
    "from snpe.simulations import simulator_class, marketplace_simulator_class\n",
    "from snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\n",
    "from snpe.utils.statistics import review_histogram_correlation\n",
    "from snpe.utils.tqdm_utils import tqdm_joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set plotting parameters\n",
    "sns.set(style=\"white\", context=\"talk\", font_scale=2.5)\n",
    "sns.set_color_codes(palette=\"colorblind\")\n",
    "sns.set_style(\"ticks\", {\"axes.linewidth\": 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c81c8d",
   "metadata": {},
   "source": [
    "Then it is time to define the path were the inference output is going to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6365b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"ARTIFACT_PATH = Path(\\\"../../..\\\")\\n\\n# Estos path de abajo ven\\u00edan de antes, el de arriba es el que te has montado para que te furule a ti\\n# ARTIFACT_PATH = Path(\\\"../../../gcs_mount/artifacts/rating_spacing_simulator\\\")\\n# ARTIFACT_PATH = Path(\\\"/data/reputation-systems/snpe/artifacts/rating_spacing_simulator\\\")\";\n",
       "                var nbb_formatted_code = \"ARTIFACT_PATH = Path(\\\"../../..\\\")\\n\\n# Estos path de abajo ven\\u00edan de antes, el de arriba es el que te has montado para que te furule a ti\\n# ARTIFACT_PATH = Path(\\\"../../../gcs_mount/artifacts/rating_spacing_simulator\\\")\\n# ARTIFACT_PATH = Path(\\\"/data/reputation-systems/snpe/artifacts/rating_spacing_simulator\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ARTIFACT_PATH = Path(\"../../..\")\n",
    "\n",
    "# Estos path de abajo venían de antes, el de arriba es el que te has montado para que te furule a ti\n",
    "# ARTIFACT_PATH = Path(\"../../../gcs_mount/artifacts/rating_spacing_simulator\")\n",
    "# ARTIFACT_PATH = Path(\"/data/reputation-systems/snpe/artifacts/rating_spacing_simulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cefe6",
   "metadata": {},
   "source": [
    "### B. Main function and its arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1627882",
   "metadata": {},
   "source": [
    "The function in the code cell below is designed to carry out inference on the basis of time series simulation output. Firstly a uniform distribution of parameters is initialized by defining the upper and lower bounds for the different parameters. Then the inferrer is instantiated (See inference_class.py) and the simulator is loaded alongside the inputs for the inference model. Lastly the inference model is trained, the posterior is built and the results are stored in the previously specified path as a .pkl file containing other relevant parameters alongside the posteriors.\n",
    "\n",
    "The arguments of the function that will have to be provided are the following:\n",
    "\n",
    "- `device`: device where the inference model will be trained. Must be str 'cuda' or 'cpu'.\n",
    "- `simulator_type`: type of the simulator to be loaded (e.g. double_herding, marketplace...).\n",
    "- `simulation_type`: modality of simulation that is to be fed to the inference model Must be str 'timeseries' or 'histogram'.\n",
    "- `params`: dictionary of parameters to configure inference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7365ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def infer_and_save_posterior(\\n    device: str, simulator_type: str, simulation_type: str, params: Dict\\n) -> None:\\n    parameter_prior = sbi_utils.BoxUniform(\\n        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(\\n            torch.FloatTensor\\n        ),\\n        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(\\n            torch.FloatTensor\\n        ),\\n        device=device,\\n    )\\n    inferrer = inference_class.TimeSeriesInference(\\n        parameter_prior=parameter_prior, device=device\\n    )\\n    inferrer.load_simulator(\\n        dirname=ARTIFACT_PATH,\\n        simulator_type=simulator_type,\\n        simulation_type=simulation_type,\\n    )\\n    batch_size = params.pop(\\\"batch_size\\\")\\n    learning_rate = params.pop(\\\"learning_rate\\\")\\n    hidden_features = params.pop(\\\"hidden_features\\\")\\n    num_transforms = params.pop(\\\"num_transforms\\\")\\n    inferrer.infer_snpe_posterior(\\n        embedding_net_conf=params,\\n        batch_size=batch_size,\\n        learning_rate=learning_rate,\\n        hidden_features=hidden_features,\\n        num_transforms=num_transforms,\\n    )\\n    inferrer.save_inference(ARTIFACT_PATH)\";\n",
       "                var nbb_formatted_code = \"def infer_and_save_posterior(\\n    device: str, simulator_type: str, simulation_type: str, params: Dict\\n) -> None:\\n    parameter_prior = sbi_utils.BoxUniform(\\n        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(\\n            torch.FloatTensor\\n        ),\\n        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(\\n            torch.FloatTensor\\n        ),\\n        device=device,\\n    )\\n    inferrer = inference_class.TimeSeriesInference(\\n        parameter_prior=parameter_prior, device=device\\n    )\\n    inferrer.load_simulator(\\n        dirname=ARTIFACT_PATH,\\n        simulator_type=simulator_type,\\n        simulation_type=simulation_type,\\n    )\\n    batch_size = params.pop(\\\"batch_size\\\")\\n    learning_rate = params.pop(\\\"learning_rate\\\")\\n    hidden_features = params.pop(\\\"hidden_features\\\")\\n    num_transforms = params.pop(\\\"num_transforms\\\")\\n    inferrer.infer_snpe_posterior(\\n        embedding_net_conf=params,\\n        batch_size=batch_size,\\n        learning_rate=learning_rate,\\n        hidden_features=hidden_features,\\n        num_transforms=num_transforms,\\n    )\\n    inferrer.save_inference(ARTIFACT_PATH)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def infer_and_save_posterior(\n",
    "    device: str, simulator_type: str, simulation_type: str, params: Dict\n",
    ") -> None:\n",
    "    parameter_prior = sbi_utils.BoxUniform(\n",
    "        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(\n",
    "            torch.FloatTensor\n",
    "        ),\n",
    "        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(\n",
    "            torch.FloatTensor\n",
    "        ),\n",
    "        device=device,\n",
    "    )\n",
    "    inferrer = inference_class.TimeSeriesInference(\n",
    "        parameter_prior=parameter_prior, device=device\n",
    "    )\n",
    "    inferrer.load_simulator(\n",
    "        dirname=ARTIFACT_PATH,\n",
    "        simulator_type=simulator_type,\n",
    "        simulation_type=simulation_type,\n",
    "    )\n",
    "    batch_size = params.pop(\"batch_size\")\n",
    "    learning_rate = params.pop(\"learning_rate\")\n",
    "    hidden_features = params.pop(\"hidden_features\")\n",
    "    num_transforms = params.pop(\"num_transforms\")\n",
    "    inferrer.infer_snpe_posterior(\n",
    "        embedding_net_conf=params,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        hidden_features=hidden_features,\n",
    "        num_transforms=num_transforms,\n",
    "    )\n",
    "    inferrer.save_inference(ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88521c7b",
   "metadata": {},
   "source": [
    "Defining the dictionary of parameters that has to be provided as argument to `infer_and_save_posterior`. The values for the parameter included below values were obtained after carrying a hyperparameter optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02c9e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# diccionario de par\\u00e1metros requerido para utilizar la funci\\u00f3n\\n\\ninference_params = {\\n    \\\"batch_size\\\": 64,\\n    \\\"learning_rate\\\": 3.1e-4,\\n    \\\"hidden_features\\\": 70,\\n    \\\"num_transforms\\\": 8,\\n    \\\"num_conv_layers\\\": 2,\\n    \\\"num_channels\\\": 9,\\n    \\\"conv_kernel_size\\\": 17,\\n    \\\"maxpool_kernel_size\\\": 11,\\n    \\\"num_dense_layers\\\": 2,\\n}\";\n",
       "                var nbb_formatted_code = \"# diccionario de par\\u00e1metros requerido para utilizar la funci\\u00f3n\\n\\ninference_params = {\\n    \\\"batch_size\\\": 64,\\n    \\\"learning_rate\\\": 3.1e-4,\\n    \\\"hidden_features\\\": 70,\\n    \\\"num_transforms\\\": 8,\\n    \\\"num_conv_layers\\\": 2,\\n    \\\"num_channels\\\": 9,\\n    \\\"conv_kernel_size\\\": 17,\\n    \\\"maxpool_kernel_size\\\": 11,\\n    \\\"num_dense_layers\\\": 2,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# diccionario de parámetros requerido para utilizar la función\n",
    "\n",
    "inference_params = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 3.1e-4,\n",
    "    \"hidden_features\": 70,\n",
    "    \"num_transforms\": 8,\n",
    "    \"num_conv_layers\": 2,\n",
    "    \"num_channels\": 9,\n",
    "    \"conv_kernel_size\": 17,\n",
    "    \"maxpool_kernel_size\": 11,\n",
    "    \"num_dense_layers\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54ccf4",
   "metadata": {},
   "source": [
    "### C. Training inference model and obtaining posterior distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939950d",
   "metadata": {},
   "source": [
    "Now that it has been defined and all the ingredients are ready we can call the main function `infer_and_save_posterior`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3589e2ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sbi/utils/torchutils.py:28: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  \"GPU was selected as a device for training the neural network. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding net created: \n",
      " Sequential(\n",
      "  (0): Conv1d(5, 9, kernel_size=(17,), stride=(1,), padding=(8,))\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Conv1d(9, 9, kernel_size=(17,), stride=(1,), padding=(16,), dilation=(2,))\n",
      "  (3): MaxPool1d(kernel_size=11, stride=11, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Flatten(start_dim=1, end_dim=-1)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=27, out_features=64, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.01)\n",
      "  (8): Linear(in_features=64, out_features=32, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sbi/utils/user_input_checks.py:697: UserWarning: Parameters theta has device 'cpu'. Moving theta to the data_device 'cuda:0'.Training will proceed on device 'cuda:0'.\n",
      "  f\"Parameters theta has device '{theta.device}'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 122 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 122\n",
      "        Best validation performance: -2.1384\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"infer_and_save_posterior(\\\"cuda\\\", \\\"marketplace\\\", \\\"timeseries\\\", inference_params)\";\n",
       "                var nbb_formatted_code = \"infer_and_save_posterior(\\\"cuda\\\", \\\"marketplace\\\", \\\"timeseries\\\", inference_params)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer_and_save_posterior(\"cuda\", \"marketplace\", \"timeseries\", inference_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac92177",
   "metadata": {},
   "source": [
    "### (Provisional/Draft) Z. Other uncommented functions and snippets to potantially incorporate to the proper notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098e30e",
   "metadata": {},
   "source": [
    "Include the following functions in the notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior_with_observed(\n",
    "    device: str,\n",
    "    observations: np.array,\n",
    "    num_samples: int,\n",
    "    simulator_type: str,\n",
    "    simulation_type: str,\n",
    ") -> np.ndarray:\n",
    "    # The parameter prior doesn't matter here as it will be overridden by that of the loaded inference object\n",
    "    parameter_prior = sbi.utils.BoxUniform(\n",
    "        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(\n",
    "            torch.FloatTensor\n",
    "        ),\n",
    "        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(\n",
    "            torch.FloatTensor\n",
    "        ),\n",
    "        device=device,\n",
    "    )\n",
    "    inferrer = inference_class.TimeSeriesInference(\n",
    "        parameter_prior=parameter_prior, device=device\n",
    "    )\n",
    "    inferrer.load_simulator(\n",
    "        dirname=ARTIFACT_PATH,\n",
    "        simulator_type=simulator_type,\n",
    "        simulation_type=simulation_type,\n",
    "    )\n",
    "    inferrer.load_inference(dirname=ARTIFACT_PATH)\n",
    "    posterior_samples = inferrer.get_posterior_samples(\n",
    "        observations, num_samples=num_samples\n",
    "    )\n",
    "    return posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In marketplace simulations, we cannot just supply a set of rho params, then simulate and infer on these simulations\n",
    "# to test if the inference can recover the initially provided params\n",
    "# So we instead sample from the posterior of a separate set of marketplace simulations not used in training and see\n",
    "# if parameters are recovered on this new set\n",
    "def sample_posterior_on_simulations(\n",
    "    device: str,\n",
    "    num_samples: int,\n",
    "    simulator_type: str,\n",
    "    simulation_type: str,\n",
    "    max_inference_length: int,\n",
    ") -> np.ndarray:\n",
    "    # We load the larger simulation (over 64 marketplaces) as the separate simulation for the inference to be tested on\n",
    "    params = {\n",
    "        \"review_prior\": np.ones(5),\n",
    "        \"tendency_to_rate\": 0.05,\n",
    "        \"simulation_type\": simulation_type,\n",
    "        \"previous_rating_measure\": \"mode\",\n",
    "        \"min_reviews_for_herding\": 5,\n",
    "        \"num_products\": 1400,\n",
    "        # \"num_products\": 100,\n",
    "        \"num_total_marketplace_reviews\": 300_000,\n",
    "        # \"num_total_marketplace_reviews\": 5_000,\n",
    "        \"consideration_set_size\": 5,\n",
    "    }\n",
    "    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\n",
    "    simulator.load_simulator(ARTIFACT_PATH / \"large_simulation\")\n",
    "    # We pick all simulations from a single marketplace as the observations on which we wish to obtain\n",
    "    # posterior samples\n",
    "    # These are the observations for the posterior sampling function defined above\n",
    "    observations = simulator.simulations[0]\n",
    "    # Also pick the simulation parameters corresponding to these simulations\n",
    "    simulation_params = simulator.simulation_parameters.copy()\n",
    "    simulation_params[\"rho\"] = simulation_params[\"rho\"][: len(observations), :]\n",
    "    simulation_params[\"h_p\"] = simulation_params[\"h_p\"][: len(observations)]\n",
    "    # Cut the observations to the max length seen during SNPE training\n",
    "    observations = np.array(\n",
    "        [obs[:max_inference_length, :] for obs in observations], dtype=\"object\"\n",
    "    )\n",
    "    posterior_samples = sample_posterior_with_observed(\n",
    "        device, observations, num_samples, simulator_type, simulation_type\n",
    "    )\n",
    "    return posterior_samples, simulation_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a6a7e",
   "metadata": {},
   "source": [
    "#### Main function - histogram (Include?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23157ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def infer_and_save_posterior(\\n    device: str, simulator_type: str, simulation_type: str, params: Dict\\n) -> None:\\n    parameter_prior = sbi_utils.BoxUniform(\\n        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(torch.FloatTensor),\\n        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(torch.FloatTensor),\\n        device=device,\\n    )\\n    inferrer = inference_class.HistogramInference(\\n        parameter_prior=parameter_prior, device=device\\n    )\\n    inferrer.load_simulator(\\n        dirname=ARTIFACT_PATH,\\n        simulator_type=simulator_type,\\n        simulation_type=simulation_type,\\n    )\\n    batch_size = params.pop(\\\"batch_size\\\")\\n    learning_rate = params.pop(\\\"learning_rate\\\")\\n    hidden_features = params.pop(\\\"hidden_features\\\")\\n    num_transforms = params.pop(\\\"num_transforms\\\")\\n    inferrer.infer_snpe_posterior(\\n        embedding_net_conf=params,\\n        batch_size=batch_size,\\n        learning_rate=learning_rate,\\n        hidden_features=hidden_features,\\n        num_transforms=num_transforms,\\n    )\\n    inferrer.save_inference(ARTIFACT_PATH)\";\n",
       "                var nbb_formatted_code = \"def infer_and_save_posterior(\\n    device: str, simulator_type: str, simulation_type: str, params: Dict\\n) -> None:\\n    parameter_prior = sbi_utils.BoxUniform(\\n        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(\\n            torch.FloatTensor\\n        ),\\n        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(\\n            torch.FloatTensor\\n        ),\\n        device=device,\\n    )\\n    inferrer = inference_class.HistogramInference(\\n        parameter_prior=parameter_prior, device=device\\n    )\\n    inferrer.load_simulator(\\n        dirname=ARTIFACT_PATH,\\n        simulator_type=simulator_type,\\n        simulation_type=simulation_type,\\n    )\\n    batch_size = params.pop(\\\"batch_size\\\")\\n    learning_rate = params.pop(\\\"learning_rate\\\")\\n    hidden_features = params.pop(\\\"hidden_features\\\")\\n    num_transforms = params.pop(\\\"num_transforms\\\")\\n    inferrer.infer_snpe_posterior(\\n        embedding_net_conf=params,\\n        batch_size=batch_size,\\n        learning_rate=learning_rate,\\n        hidden_features=hidden_features,\\n        num_transforms=num_transforms,\\n    )\\n    inferrer.save_inference(ARTIFACT_PATH)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def infer_and_save_posterior(\n",
    "#    device: str, simulator_type: str, simulation_type: str, params: Dict\n",
    "#) -> None:\n",
    "#    parameter_prior = sbi_utils.BoxUniform(\n",
    "#        low=torch.tensor([0.0, 0.0, 0.0, 0.0, 0.5, 0.25, 0.25, 0.5]).type(torch.FloatTensor),\n",
    "#        high=torch.tensor([4.0, 4.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0]).type(torch.FloatTensor),\n",
    "#        device=device,\n",
    "#    )\n",
    "#    inferrer = inference_class.HistogramInference(\n",
    "#        parameter_prior=parameter_prior, device=device\n",
    "#    )\n",
    "#    inferrer.load_simulator(\n",
    "#        dirname=ARTIFACT_PATH,\n",
    "#        simulator_type=simulator_type,\n",
    "#        simulation_type=simulation_type,\n",
    "#    )\n",
    "#    batch_size = params.pop(\"batch_size\")\n",
    "#    learning_rate = params.pop(\"learning_rate\")\n",
    "#    hidden_features = params.pop(\"hidden_features\")\n",
    "#    num_transforms = params.pop(\"num_transforms\")\n",
    "#    inferrer.infer_snpe_posterior(\n",
    "#        embedding_net_conf=params,\n",
    "#        batch_size=batch_size,\n",
    "#        learning_rate=learning_rate,\n",
    "#        hidden_features=hidden_features,\n",
    "#        num_transforms=num_transforms,\n",
    "#    )\n",
    "#    inferrer.save_inference(ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1135ad68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sbi/utils/torchutils.py:28: UserWarning: GPU was selected as a device for training the neural network. Note that we expect **no** significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  \"GPU was selected as a device for training the neural network. \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41/3491754300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfer_and_save_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"marketplace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"histogram\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_41/3475302786.py\u001b[0m in \u001b[0;36minfer_and_save_posterior\u001b[0;34m(device, simulator_type, simulation_type, params)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhidden_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mnum_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[0minferrer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARTIFACT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/rating_spacing/reputation-systems/snpe/snpe/inference/inference_class.py\u001b[0m in \u001b[0;36minfer_snpe_posterior\u001b[0;34m(self, embedding_net_creator, embedding_net_conf, simulation_transform, model, batch_size, learning_rate, hidden_features, num_transforms)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0msimulations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0msimulations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Add the length of the padded simulations (if timeseries) for later use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"timeseries\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"infer_and_save_posterior(\\\"cuda\\\", \\\"marketplace\\\", \\\"histogram\\\", inference_params)\";\n",
       "                var nbb_formatted_code = \"infer_and_save_posterior(\\\"cuda\\\", \\\"marketplace\\\", \\\"histogram\\\", inference_params)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#infer_and_save_posterior(\"cuda\", \"marketplace\", \"histogram\", inference_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
